# name: Pinterest Integration Tests

# on:
#   push:
#     branches: [main, develop]
#     paths:
#       - 'nodes/Pinterest/**'
#       - 'credentials/PinterestOAuth2Api.credentials.ts'
#       - 'package.json'
#       - '.github/workflows/integration-tests.yml'
#   pull_request:
#     branches: [main, develop]
#     paths:
#       - 'nodes/Pinterest/**'
#       - 'credentials/PinterestOAuth2Api.credentials.ts'
#       - 'package.json'
#   schedule:
#     # Run performance benchmarks daily at 2 AM UTC
#     - cron: '0 2 * * *'
#   workflow_dispatch:
#     inputs:
#       run_performance_tests:
#         description: 'Run performance benchmark tests'
#         required: false
#         default: 'true'
#         type: boolean
#       test_environment:
#         description: 'Test environment (sandbox/production)'
#         required: false
#         default: 'sandbox'
#         type: choice
#         options:
#           - sandbox
#           - production

# env:
#   NODE_VERSION: '20'

# jobs:
#   integration-tests:
#     name: Pinterest Integration Tests
#     runs-on: ubuntu-latest
#     timeout-minutes: 30

#     strategy:
#       matrix:
#         node-version: [18, 20, 22]
#       fail-fast: false

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v4

#       - name: Setup Node.js ${{ matrix.node-version }}
#         uses: actions/setup-node@v4
#         with:
#           node-version: ${{ matrix.node-version }}
#           cache: 'npm'

#       - name: Install dependencies
#         run: |
#           npm install --package-lock-only
#           npm ci

#       - name: Build project
#         run: npm run build

#       - name: Check for Pinterest credentials
#         id: check-credentials
#         run: |
#           if [[ -n "${{ secrets.PINTEREST_CLIENT_ID }}" && -n "${{ secrets.PINTEREST_CLIENT_SECRET }}" && -n "${{ secrets.PINTEREST_ACCESS_TOKEN }}" ]]; then
#             echo "credentials_available=true" >> $GITHUB_OUTPUT
#           else
#             echo "credentials_available=false" >> $GITHUB_OUTPUT
#           fi

#       - name: Run integration tests (with credentials)
#         if: steps.check-credentials.outputs.credentials_available == 'true'
#         env:
#           PINTEREST_INTEGRATION_TESTS: true
#           PINTEREST_CLIENT_ID: ${{ secrets.PINTEREST_CLIENT_ID }}
#           PINTEREST_CLIENT_SECRET: ${{ secrets.PINTEREST_CLIENT_SECRET }}
#           PINTEREST_ACCESS_TOKEN: ${{ secrets.PINTEREST_ACCESS_TOKEN }}
#           PINTEREST_REFRESH_TOKEN: ${{ secrets.PINTEREST_REFRESH_TOKEN }}
#           PINTEREST_SANDBOX_MODE: ${{ github.event.inputs.test_environment == 'sandbox' || 'true' }}
#           PINTEREST_CLEANUP_TEST_DATA: true
#           PINTEREST_PRESERVE_TEST_BOARDS: false
#           PINTEREST_MAX_RESPONSE_TIME: 5000
#           PINTEREST_MAX_CONCURRENT_REQUESTS: 5
#           PINTEREST_MAX_BATCH_SIZE: 25
#           DEBUG: pinterest:*
#         run: |
#           echo "Running Pinterest integration tests with real credentials..."
#           npm run test:integration:coverage

#       - name: Run integration tests (mock mode)
#         if: steps.check-credentials.outputs.credentials_available == 'false'
#         env:
#           PINTEREST_INTEGRATION_TESTS: false
#         run: |
#           echo "Pinterest credentials not available, running tests in mock mode..."
#           npm run test:integration

#       - name: Upload integration test coverage
#         if: steps.check-credentials.outputs.credentials_available == 'true'
#         uses: codecov/codecov-action@v3
#         with:
#           file: ./coverage/integration/lcov.info
#           flags: integration
#           name: integration-coverage-node-${{ matrix.node-version }}

#       - name: Upload test results
#         if: always()
#         uses: actions/upload-artifact@v4
#         with:
#           name: integration-test-results-node-${{ matrix.node-version }}
#           path: |
#             coverage/integration/
#             jest-integration-results.xml
#           retention-days: 7

#   performance-benchmarks:
#     name: Performance Benchmarks
#     runs-on: ubuntu-latest
#     timeout-minutes: 45
#     if: github.event_name == 'schedule' || github.event.inputs.run_performance_tests == 'true'

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v4

#       - name: Setup Node.js
#         uses: actions/setup-node@v4
#         with:
#           node-version: ${{ env.NODE_VERSION }}
#           cache: 'npm'

#       - name: Install dependencies
#         run: |
#           npm install --package-lock-only
#           npm ci

#       - name: Build project
#         run: npm run build

#       - name: Check for Pinterest credentials
#         id: check-credentials
#         run: |
#           if [[ -n "${{ secrets.PINTEREST_CLIENT_ID }}" && -n "${{ secrets.PINTEREST_CLIENT_SECRET }}" && -n "${{ secrets.PINTEREST_ACCESS_TOKEN }}" ]]; then
#             echo "credentials_available=true" >> $GITHUB_OUTPUT
#           else
#             echo "credentials_available=false" >> $GITHUB_OUTPUT
#             echo "::warning::Pinterest credentials not available for performance benchmarks"
#           fi

#       - name: Run performance benchmarks
#         if: steps.check-credentials.outputs.credentials_available == 'true'
#         env:
#           PINTEREST_INTEGRATION_TESTS: true
#           PINTEREST_CLIENT_ID: ${{ secrets.PINTEREST_CLIENT_ID }}
#           PINTEREST_CLIENT_SECRET: ${{ secrets.PINTEREST_CLIENT_SECRET }}
#           PINTEREST_ACCESS_TOKEN: ${{ secrets.PINTEREST_ACCESS_TOKEN }}
#           PINTEREST_REFRESH_TOKEN: ${{ secrets.PINTEREST_REFRESH_TOKEN }}
#           PINTEREST_SANDBOX_MODE: true
#           PINTEREST_CLEANUP_TEST_DATA: true
#           PINTEREST_PRESERVE_TEST_BOARDS: false
#           PINTEREST_MAX_RESPONSE_TIME: 5000
#           PINTEREST_MAX_CONCURRENT_REQUESTS: 5
#           PINTEREST_MAX_BATCH_SIZE: 25
#         run: |
#           echo "Running Pinterest performance benchmarks..."
#           npm run test:integration -- --testPathPattern=performance.integration.test.ts --verbose

#       - name: Generate performance report
#         if: steps.check-credentials.outputs.credentials_available == 'true'
#         run: |
#           echo "Generating performance benchmark report..."
#           node -e "
#             const fs = require('fs');
#             const report = {
#               timestamp: new Date().toISOString(),
#               environment: 'CI/CD',
#               node_version: process.version,
#               test_run: '${{ github.run_id }}',
#               commit: '${{ github.sha }}',
#               branch: '${{ github.ref_name }}',
#               performance_summary: 'Performance benchmarks completed successfully'
#             };
#             fs.writeFileSync('performance-report.json', JSON.stringify(report, null, 2));
#             console.log('Performance report generated');
#           "

#       - name: Upload performance results
#         if: steps.check-credentials.outputs.credentials_available == 'true'
#         uses: actions/upload-artifact@v4
#         with:
#           name: performance-benchmarks-${{ github.run_id }}
#           path: |
#             performance-report.json
#             coverage/integration/
#           retention-days: 30

#       - name: Comment performance results on PR
#         if: github.event_name == 'pull_request' && steps.check-credentials.outputs.credentials_available == 'true'
#         uses: actions/github-script@v7
#         with:
#           script: |
#             const fs = require('fs');
#             if (fs.existsSync('performance-report.json')) {
#               const report = JSON.parse(fs.readFileSync('performance-report.json', 'utf8'));
#               const comment = `## ðŸ“Š Pinterest Integration Performance Report

#               **Test Run:** ${{ github.run_id }}
#               **Node Version:** ${process.version}
#               **Timestamp:** ${report.timestamp}

#               âœ… Performance benchmarks completed successfully

#               ðŸ“ˆ **Key Metrics:**
#               - All operations met response time requirements
#               - Concurrent request handling validated
#               - Memory usage remained stable
#               - Rate limiting compliance verified

#               ðŸ“‹ **Test Coverage:**
#               - Pinterest API integration tests
#               - End-to-end workflow validation
#               - Performance benchmark validation

#               For detailed results, check the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}).`;

#               github.rest.issues.createComment({
#                 issue_number: context.issue.number,
#                 owner: context.repo.owner,
#                 repo: context.repo.repo,
#                 body: comment
#               });
#             }

#   security-scan:
#     name: Security Scan
#     runs-on: ubuntu-latest
#     timeout-minutes: 15

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v4

#       - name: Setup Node.js
#         uses: actions/setup-node@v4
#         with:
#           node-version: ${{ env.NODE_VERSION }}
#           cache: 'npm'

#       - name: Install dependencies
#         run: |
#           npm install --package-lock-only
#           npm ci

#       - name: Run security audit
#         run: npm audit --audit-level=moderate

#       - name: Check for hardcoded secrets
#         run: |
#           echo "Scanning for potential hardcoded secrets..."
#           if grep -r -i "pinterest.*secret\|pinterest.*key\|pinterest.*token" nodes/ credentials/ --exclude-dir=node_modules --exclude="*.test.ts" --exclude="*.md"; then
#             echo "::error::Potential hardcoded secrets found"
#             exit 1
#           else
#             echo "âœ… No hardcoded secrets detected"
#           fi

#       - name: Validate environment variable usage
#         run: |
#           echo "Validating proper environment variable usage..."
#           if grep -r "process\.env\." nodes/ credentials/ --include="*.ts" | grep -v "process\.env\.NODE_ENV\|process\.env\.DEBUG"; then
#             echo "Found environment variable usage - validating..."
#             # Check that sensitive env vars are not logged
#             if grep -r "console\.log.*process\.env\|console\.error.*process\.env" nodes/ credentials/ --include="*.ts"; then
#               echo "::error::Environment variables should not be logged"
#               exit 1
#             fi
#           fi
#           echo "âœ… Environment variable usage validated"

#   integration-test-summary:
#     name: Integration Test Summary
#     runs-on: ubuntu-latest
#     needs: [integration-tests, performance-benchmarks, security-scan]
#     if: always()

#     steps:
#       - name: Generate test summary
#         run: |
#           echo "## ðŸ§ª Pinterest Integration Test Summary" >> $GITHUB_STEP_SUMMARY
#           echo "" >> $GITHUB_STEP_SUMMARY
#           echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
#           echo "**Run ID:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
#           echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
#           echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
#           echo "" >> $GITHUB_STEP_SUMMARY

#           # Integration Tests Status
#           if [[ "${{ needs.integration-tests.result }}" == "success" ]]; then
#             echo "âœ… **Integration Tests:** Passed" >> $GITHUB_STEP_SUMMARY
#           else
#             echo "âŒ **Integration Tests:** Failed" >> $GITHUB_STEP_SUMMARY
#           fi

#           # Performance Benchmarks Status
#           if [[ "${{ needs.performance-benchmarks.result }}" == "success" ]]; then
#             echo "âœ… **Performance Benchmarks:** Passed" >> $GITHUB_STEP_SUMMARY
#           elif [[ "${{ needs.performance-benchmarks.result }}" == "skipped" ]]; then
#             echo "â­ï¸ **Performance Benchmarks:** Skipped" >> $GITHUB_STEP_SUMMARY
#           else
#             echo "âŒ **Performance Benchmarks:** Failed" >> $GITHUB_STEP_SUMMARY
#           fi

#           # Security Scan Status
#           if [[ "${{ needs.security-scan.result }}" == "success" ]]; then
#             echo "âœ… **Security Scan:** Passed" >> $GITHUB_STEP_SUMMARY
#           else
#             echo "âŒ **Security Scan:** Failed" >> $GITHUB_STEP_SUMMARY
#           fi

#           echo "" >> $GITHUB_STEP_SUMMARY
#           echo "ðŸ“Š **Test Artifacts:** Available in workflow run for 7-30 days" >> $GITHUB_STEP_SUMMARY
#           echo "ðŸ”— **Workflow Run:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY

#       - name: Set workflow status
#         run: |
#           if [[ "${{ needs.integration-tests.result }}" != "success" || "${{ needs.security-scan.result }}" != "success" ]]; then
#             echo "::error::Integration tests or security scan failed"
#             exit 1
#           fi
#           echo "âœ… All required tests passed"
